# coding:utf8
# linear layer output 3; age (0,50); test sample num (5000);
# Computing slows down when "test sample num" be very large, e.g. 100,000
# irrelevance acc with sample size
# 不管怎么调，准确率就只有80%
# 学习率20的时候，准确率就上下乱跳了
# 学习率0.000001的时候，loss下将得特别慢
# 学习率调整到0.1的时候，准确率96%
# input size == 100: RuntimeError: mat1 and mat2 shapes cannot be multiplied (10x1 and 100x100)
# input size 只能是 1？
# batch size == 100 每次训练批次中的样本量越大，梯度下降越快，刚开始准确率上下波动较大，而后准确率快速提高，
# batch size == 500 的时候，梯度效率更加高
# batch size == 1000 的时候，就报错了？
# line 33 and line 103 中的输出维度为什么可以不同？不影响计算？
# 为什么不能打印图像： # visualize the training logs by plotting the accuracy and loss curves
#     print(log) # prints out the log variable which contains the training metrics
#     plt.plot(range(len(log)), [l[0] for l in log], label="acc")  # 画acc曲线
#     plt.plot(range(len(log)), [l[1] for l in log], label="loss")  # 画loss曲线
#     plt.legend()
#     plt.show()
#     return


# import library
import torch
import torch.nn as nn
import numpy as np
import random
import json
import matplotlib.pyplot as plt
import matplotlib_inline
import numpy

class TorchModel(nn.Module):
    def __init__(self, input_size):
        super(TorchModel, self).__init__()
        self.linear = nn.Linear(input_size, 1)  # 定义线性层；The linear layer does the main computation；a linear layer with 3 output units
        self.activation = nn.Softmax(dim=1)  # 定义激活函数；Softmax converts outputs to probabilities；dim有什么用，该了数值对准确率没影响？
        self.loss = nn.CrossEntropyLoss()  # 定义损失函数，交叉熵；Cross entropy loss measures performance

    def forward(self, x, y=None):
        x = self.linear(x)  # pass input through linear layer and get row scores; linear layer output (batch size, 3)
        y_pred = self.activation(x)  # Apply softmax activation to get predicted probabilities; take linear layout output, apply softmax, shape (batch size, 3), normalized between 0 and 1
        if y is not None: # compute loss between predictions or loss
            return self.loss(y_pred, y)  # return loss value to optimize
        else:
            return y_pred  # return predictions

# creating synthetic datasets to test machine learning models
def build_sample(): # generate a random sample and label
    age = np.random.randint(0, 100)  # generate random age 0-29
    if age <= 12: # assign a label, Labels divided into 3 classes based on age
        label = 0  # kid
    elif 12 < age <= 20:
        label = 1  # youth
    else:
        label = 2  # adult
    x = np.array([age]) # create input feature vector x; convert age list to a numpy array
    return x, label # the randomly generating (age, label) pairs to train a model to predict age categories

# build datasets
# it generates multiple random samples using build_sample(), aggregates them into full matrices X and Y, converts them to Tensors, and returns the full dataset.
# The samples will have 1 feature (age) and 1 of 3 labels (kid, youth, adult)
# This dataset can then be used to fit and test a classification model
def build_dataset(total_sample_num): # Initialize empty lists to store samples
    X = [] # X will store the feature vectors
    Y = [] # Y will store the labels
    for i in range(total_sample_num): # Generate samples in a loop
        x, y = build_sample()
        X.append(x)
        Y.append(y)
    return torch.FloatTensor(X), torch.LongTensor(Y) # Convert X to torch.FloatTensor; Convert Y to torch.LongTensor
# Return the dataset: X contains the complete feature matrix; Y contains the complete labels

# 测试代码
# 用来测试每轮模型的准确率
# evaluate the performance of a classification model on a test set
# ACCURACY
# it generates a test set, makes predictions using the model, compares them to true labels to count correct/wrong, and calculates the accuracy.
# This is a common pattern for evaluating classification model performance on a test set.
# The key steps are making predictions, comparing to true labels, and calculating accuracy metrics.
def evaluate(model):
    model.eval() # Put model in evaluation mode
    test_sample_num = 10000 # Generate a test samples
    x, y = build_dataset(test_sample_num)
    print("Test set has %d kid, %d youth, %d adult samples" % (sum(y == 0), sum(y == 1), sum(y == 2)))
    correct, wrong = 0, 0 # Initialize counters for correct and wrong predictions
    with torch.no_grad(): # Make predictions on the test set using model(x) and no gradient tracking.
        y_pred = model(x)  # 模型预测
        for y_p, y_t in zip(y_pred, y):  # 与真实标签进行对比 Loop through predictions and compare to true labels
            if y_p.argmax() == y_t: # Get predicted class index
                correct += 1  # 负样本判断正确 Check if equals true label y_t
            else:
                wrong += 1 # Increment correct or wrong counters accordingly
    print("Correct prediction: %d, Accuracy: %f" % (correct, correct / (correct + wrong))) # Print accuracy = correct / total
    return correct / (correct + wrong) # Return accuracy as final result

# main training loop for a neural network classifier:
# - Defines hyperparameters
# - Builds the model, optimizer, loss
# - Generates training data
# - Implements the training loop with forward/backward passes
# - Evaluates after each epoch
# - Logs metrics
def main():
    # 配置参数 Configure hyperparameters
    epoch_num = 50  # 训练轮数 Number of training epochs
    batch_size = 500  # 每次训练样本个数 Batch size for training
    train_sample = 500  # 每轮训练总共训练的样本总数 Total training samples per epoch
    input_size = 1  # 输入向量维度 Input dimension
    learning_rate = 0.1  # 学习率 Learning rate for optimizer
    # 建立模型 Build model, optimizer, loss function
    model = nn.Sequential (nn.Linear(input_size,5), nn.ReLU(), nn.Linear (5,3)) # select model: A simple Sequential model with 2 linear layers
    # 选择优化器 optim
    optim = torch.optim.Adam(model.parameters(), lr=learning_rate) # select optim: Adam optimizer using defined learning rate
    criterion = nn.CrossEntropyLoss() # select criterion: CrossEntropyLoss
    log = []
    # 创建训练集，正常任务是读取训练集
    train_x, train_y = build_dataset(train_sample) # 调用 Generate training data
    # 训练过程 Training loop
    for epoch in range(epoch_num): # Loop over epochs
        model.train() # Inside each epoch
        watch_loss = []
        for batch_index in range(train_sample // batch_size): # Loop over batches; Get batch data
            x = train_x[batch_index * batch_size: (batch_index + 1) * batch_size]
            y = train_y[batch_index * batch_size: (batch_index + 1) * batch_size]
            y_pred = model(x) # make prediction
            loss = criterion(y_pred, y)
            loss.backward()  # 计算梯度 Calculate loss
            if batch_index % 2 == 0:
                optim.step()  # 更新权重 Backprop to get gradients
                optim.zero_grad()  # 梯度归零 # update weights every 2 batches
            watch_loss.append(loss.item()) # Track average loss
        print("=========\n round % d in average loss:%f" % (epoch + 1, np.mean(watch_loss)))
        acc = evaluate(model)  # 测试本轮模型结果 Evaluate model on test set after each epoch
        log.append([acc, float(np.mean(watch_loss))]) # Log accuracy and loss after each epoch 为什么要log

    # 保存模型
    torch.save(model.state_dict(), "model.pth")

# visualize the training logs by plotting the accuracy and loss curves
    print(log) # prints out the log variable which contains the training metrics
    plt.plot(range(len(log)), [l[0] for l in log], label="acc")  # 画acc曲线
    plt.plot(range(len(log)), [l[1] for l in log], label="loss")  # 画loss曲线
    plt.legend()
    plt.show()
    return

main()
